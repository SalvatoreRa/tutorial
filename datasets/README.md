# Datasets
## Datasets for machine learning

![Library](https://images.unsplash.com/photo-1521587760476-6c12a4b040da?ixlib=rb-1.2.1&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=1170&q=80)

Photo by [IÃ±aki del Olmo](https://unsplash.com/@szmigieldesign) on [Unsplash](https://unsplash.com/@inakihxz)

&nbsp;

# Index of the section

* [Introduction](#Introduction)

# Introduction

In this section, you will find a collection of datasets for machine learning project. I am curating here a selection of datasets that you can use for different tasks and that I am using in my tutorials. I am adding also some notebooks where I show and explain in detail the dataset (making it easy to use them). Check the **Google Colab** notebook, I am presenting the dataset providing information (history, context, additional information) but also showing visualization techniques for exploratory data analysis. The idea is that an ML beginner (but also one who is interested in data science) can find a selection of datasets appropriate for different tasks: Moreover, the notebook can help to have a quick view of the datasets, to gain data visualization ideas. In addition, I am using these datasets in my tutorial on Machine learning and artificial intelligence, providing real case uses and explaining in detail the algorithm.

I am storing here the datasets as CSV files, if bigger than 50 MB I uploading the zip file. Check below how to import in Colab a zip file.

I will add other datasets soon. You may write me with any requests, suggestions, and comments.

# Possible tasks

You find here datasets for these possible tasks:
* Binary tabular classification
* Multi-class tabular classification
* Tabular regression
* Survival analysis (special case of regression)
* Graph node classification
* Text classification

# Datasets and Notebooks

Here are listed all the datasets in this repository, there is also the associated Google Colab file. Check also the first notebook to quickly check how to load any of these datasets.

| #| Dataset | Notebook | Source | Description |
| -| ------- | ----------- | ------ |------ |
| -| [Quick look up](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/Quick_lookup.ipynb) | [Notebook](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/Quick_lookup.ipynb) | --- | A quick look up to how to read any of the datasets - NOTEBOOK in construction|
| 1. | [Boston house price](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/Boston.csv) | --- | [source](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html) | Dataset for regression - NOTEBOOK NOT READY YET|
| 2.| [White wine dataset](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/winequality-white.csv) | [Notebook](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/wine_dataset.ipynb)| [source](https://archive.ics.uci.edu/ml/datasets/wine) | Dataset for regression/classification - NOTEBOOK NOT READY YET|
| 3.| [Red wine dataset](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/winequality-red.csv) | --- | [source](https://archive.ics.uci.edu/ml/datasets/wine) | Dataset for regression/classification - NOTEBOOK NOT READY YET|
| 4.| [Titanic dataset](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/titanic.csv) | --- | [source](https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/problem12.html) | Dataset for classification - NOTEBOOK NOT READY YET|
| 5.| [IMDB review](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/IMDB.zip) | [Notebook](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/IMDB_dataset.ipynb) | [source](https://archive.ics.uci.edu/ml/datasets/wine) | Dataset for sentimental analysis, NLP tasks |
| 6.| [Word cities](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/worldcities.csv) | [Notebook](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/word_cities_dataset.ipynb) | [source](https://archive.ics.uci.edu/ml/datasets/wine) | Dataset of the cities in the world |
| 7.| [Credit Fraud Detection](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/credit_card.csv) | [Notebook](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/credit_fraud.ipynb) | [source](https://mlg.ulb.ac.be/wordpress/portfolio_page/defeatfraud-assessment-and-validation-of-deep-feature-engineering-and-learning-solutions-for-fraud-detection/) | imbalanced dataset |
| 8.| [Penguin](https://raw.githubusercontent.com/SalvatoreRa/tutorial/main/datasets/penguins.csv) | --- | [source](https://cran.r-project.org/web/packages/palmerpenguins/readme/README.html) | classification of the penguin species- NOTEBOOK NOT READY YET|
| 9.| [Mushroom](https://raw.githubusercontent.com/SalvatoreRa/tutorial/main/datasets/mushrooms.csv) | --- | [source](https://archive.ics.uci.edu/ml/datasets/mushroom) | classification of the mushroom species- NOTEBOOK NOT READY YET|
| 10.| [Iris dataset](https://raw.githubusercontent.com/SalvatoreRa/tutorial/main/datasets/iris_flowers.csv) | --- | [source](https://archive.ics.uci.edu/ml/datasets/mushroom) | classification of the mushroom species- NOTEBOOK NOT READY YET|
| 11.| [FIF21 dataset](https://raw.githubusercontent.com/SalvatoreRa/tutorial/main/datasets/FIFA_players_21.csv) | --- | [source](https://www.kaggle.com/stefanoleone992/fifa-21-complete-player-dataset?select=players_21.csv) | FIF21 player from Kaggle- NOTEBOOK NOT READY YET|
| 12.| [CORA dataset: network](https://raw.githubusercontent.com/SalvatoreRa/tutorial/main/datasets/cora.cites)| --- | [source](https://linqs.soe.ucsc.edu/data) | citation network of scientific articles (two files: network and node attributes)|
|   |[CORA dataset: Node features](https://raw.githubusercontent.com/SalvatoreRa/tutorial/main/datasets/cora.content) | --- | [source](https://linqs.soe.ucsc.edu/data) | citation network of scientific articles (two files: network and node attributes)|
| 13.| [Census Income](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/adult.csv)| --- | [source]([https://linqs.soe.ucsc.edu/data](https://www.kaggle.com/datasets/uciml/adult-census-income)) |This data was extracted from the 1994 Census bureau database by Ronny Kohavi and Barry Becker (Data Mining and Visualization, Silicon Graphics). The prediction task is to determine whether a person makes over $50K a year. [Alternative source](https://archive.ics.uci.edu/dataset/2/adult)|
| 14.| [Faults](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/faults.csv)| --- | [source](https://www.kaggle.com/datasets/shrutimechlearn/steel-plate-fault) |small size dataset where the target variable is multi-class, ideal for starting with multi-class classification |
| 15.| [Salary IoT](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/Salary_Data_Based_country_and_race.csv)| --- | [source](https://www.kaggle.com/datasets/sudheerp2147234/salary-dataset-based-on-country-and-race?select=Salary_Data_Based_country_and_race.csv) |The dataset consists of a comprehensive collection of salary and demographic information with additional details on years of experience. It offers a valuable resource for studying the relationship between income and various socio-demographic factors. The demographic attributes include age, gender, education, country, and race, providing a diverse range of variables for analysis. Researchers can explore patterns and trends in income distribution across different demographic categories, allowing for insights into potential disparities or variations in earning potential.  |
| 16.| [Interstate Traffic Dataset](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/Metro_Interstate_Traffic_Volume.zip)| --- | [source](https://www.kaggle.com/datasets/anshtanwar/metro-interstate-traffic-volume) |This dataset contains hourly data on the traffic volume for westbound I-94, a major interstate highway in the US that connects Minneapolis and St Paul, Minnesota. The data was collected by the Minnesota Department of Transportation (MnDOT) from 2012 to 2018 at a station roughly midway between the two cities. The dataset has 48204 instances and 9 attributes.   |
| 17.| [Indian college reviews](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/Indian_college_reviews.zip)| --- | [source](https://www.kaggle.com/datasets/prateekkhandelwal18/indian-college-reviews) |This dataset contains all the Engineering college reviews for colleges in India. I scraped the data from the Collegedunia website. The data contains 4 variables: Username, College name, Review, Rating  |
| 18.| [Nuclear_Explosions_Data](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/Nuclear_Explosions_Data.zip)| --- | [source](https://www.kaggle.com/datasets/utkarshx27/nuclear-explosions-data) |Details of all nuclear explosions prior to 2000. information about the source, weapon source country, Region where the nuclear device was deployed, Longitude and Latitudine position, the magnitude of the explosion, Surface wave magnitude, power, and so on   |
| 19.| [World Airports](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/World_Airports.zip)| --- | [source](https://www.kaggle.com/datasets/mexwell/world-airports) |Airports of the world with information about codenames, elevation, frequency, runways and Wikipedia links.  zip file (file: csv)|
| 20.| [CO2 Emissions](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/CO2%20Emissions.zip)| --- | [source](https://www.kaggle.com/datasets/bhuviranga/co2-emissions) |car emission CO2, variable includes the carmaker, vehicle, type of vehicle, engine and so on.  zip file (file: csv)|
| 21.| [Global Stock Market (2008-2023)](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/Global_Stock_Market%20_2008_2023.zip)| --- | [source](https://www.kaggle.com/datasets/pavankrishnanarne/global-stock-market-2008-present) |This dataset encompasses daily price and volume data from several major global stock indices and commodities for the period of 2008 to 2023. The dataset includes the most important stock exchanges. It can be used for financial analysis, trading strategies, machine learning models, and interconnections between the markets.zip file (file: CSV)|
| 22.| [pol](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/pol.csv)| --- | [source](https://www.openml.org/search?type=data&sort=runs&id=722&status=active) |Binarized version of the original data set. It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N'). (file: CSV)|
| 23.| [Breast cancer](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/breast_cancer.csv)| --- | [source](https://github.com/sebp/scikit-survival/tree/v0.22.1/sksurv/datasets) |The dataset has 198 examples and 80 features, the last two columns represent time and event (metastasis appearance), information on the datasets: [here](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE7390) and [here](https://pubmed.ncbi.nlm.nih.gov/17545524/) (file: CSV)|
| 24.| [AIDS progression](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/aids_progression.csv)| --- | [source](https://github.com/sebp/scikit-survival/tree/v0.22.1/sksurv/datasets)  | 1,151 samples and 11 features, the last two columns represent time and event, there are two different outcomes: progression and death. To make the usage easier, the datasets are separated. Additional information on the dataset: [here](https://web.archive.org/web/20170114043458/http://www.umass.edu/statdata/statdata/data/) and [here](https://onlinelibrary.wiley.com/doi/book/10.1002/9780470258019)  (file: CSV)|
| 25.| [AIDS death](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/aids_progression.csv)| --- | [source](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/aids_death.csv)  | 1,151 samples and 11 features, the last two columns represent time and event, there are two different outcomes: progression and death. To make the usage easier, the datasets are separated. Additional information on the dataset: [here](https://web.archive.org/web/20170114043458/http://www.umass.edu/statdata/statdata/data/) and [here](https://onlinelibrary.wiley.com/doi/book/10.1002/9780470258019) (file: CSV)|
| 26.| [flchain](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/flchain.csv)| --- | [source](https://github.com/sebp/scikit-survival/tree/v0.22.1/sksurv/datasets)  | 7874 samples and 9 features. the last two columns represent time and event (death for 215 patients), additional info: [here](https://doi.org/10.1016/j.mayocp.2012.03.009) and [here](https://pubmed.ncbi.nlm.nih.gov/22677072/) (file: CSV)|
| 27.| [gbsg2](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/gbsg2.csv)| --- | [source](https://github.com/sebp/scikit-survival/tree/v0.22.1/sksurv/datasets) 6 | 86 samples and 8 features. the last two columns represent time and event (recurrence of the disease for 299 patients), additional info: [here](http://ascopubs.org/doi/abs/10.1200/jco.1994.12.10.2086) and [here](https://pubmed.ncbi.nlm.nih.gov/7931478/)(file: CSV)|
| 28.| [hnscc](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/hnscc.csv)| --- | [source](https://github.com/sebp/scikit-survival/tree/v0.22.1/sksurv/datasets)  |451 samples and 14 features. the last two columns represent time and event (death), additional info: [here](https://wiki.cancerimagingarchive.net/display/Public/HNSCC) and [here](https://openreview.net/pdf?id=LW-QxwZWSss) (file: CSV)|
| 29.| [veterans_lung_cancer](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/veterans_lung_cancer.csv)| --- | [source](https://github.com/sebp/scikit-survival/tree/v0.22.1/sksurv/datasets) 1| 37 samples and 6 features. the last two columns represent time and event (death for 128 patients), additional info: [here](https://onlinelibrary.wiley.com/doi/book/10.1002/9781118032985) (file: CSV)|
| 30.| [whas500](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/whas500.csv)| --- | [source.](https://github.com/sebp/scikit-survival/tree/v0.22.1/sksurv/datasets) |500 samples and 14 features. the last two columns represent time and event (death for 215 patients), additional info: [here](https://web.archive.org/web/20170114043458/http://www.umass.edu/statdata/statdata/data/) and [here](https://onlinelibrary.wiley.com/doi/book/10.1002/9780470258019) (file: CSV)|
| 31.| [Long](https://raw.githubusercontent.com/SalvatoreRa/tutorial/main/datasets/long.csv)| --- | [source.](https://www.openml.org/search?type=data&status=active&id=42636) | Data for a stock long position. 20 features and 4477, last column target variable. All features are numeric and no categorical features (file: CSV)|
| 32.| [Long](https://raw.githubusercontent.com/SalvatoreRa/tutorial/main/datasets/heloc.csv)| --- | [source.](https://www.openml.org/search?type=data&sort=runs&id=45026) | This dataset belongs to the "classification on numerical features" benchmark. 10000 examples and 22 features. All features are numeric and no categorical features (file: CSV)|
| 33.| [house_16H](https://raw.githubusercontent.com/SalvatoreRa/tutorial/main/datasets/house_16H.csv)| --- | [source.](https://www.openml.org/search?type=data&sort=runs&id=821) | This dataset belongs to the "classification on numerical features" benchmark. 13488 examples and 16 features. All features are numeric and no categorical features (file: CSV)|
| 34.| [MagicTelescope](https://raw.githubusercontent.com/SalvatoreRa/tutorial/main/datasets/MagicTelescope.csv)| --- | [source.](https://www.openml.org/search?type=data&sort=runs&id=1120) | This dataset belongs to the "classification on numerical features" benchmark. The data set was generated by a Monte Carlo program, to simulate the registration of high-energy gamma particles in a ground-based atmospheric Cherenkov gamma telescope using the imaging technique.  13376 examples and 10 features. All features are numeric and no categorical features (file: CSV)|
|35. |[Mammoth 3D](https://raw.githubusercontent.com/SalvatoreRa/tutorial/main/datasets/mammoth_3d.json)| --- |[source](https://github.com/YingfanWang/PaCMAP/tree/master)| A 3D dataset to check dimensional dimension techniques (file: JSON). [Original article](https://arxiv.org/abs/2012.04456)|
|36. |[Netflix Movies and TV Shows](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/Netflix_Movies_and_TV_Shows.zip)| --- |[source](https://www.kaggle.com/datasets/rahulvyasm/netflix-movies-and-tv-shows)| A comprehensive compilation of movies and TV shows available on Netflix, feature represents title type, director, cast, country of production, release year, rating, duration, genres (listed in), and a brief description. Total features 12, total examples: 8,809 entries. (file: ZIP). |
|37. |[Coronavirus tweets](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/Coronavirus_tweets.zip)| --- |[source](https://www.kaggle.com/datasets/datatattle/covid-19-nlp-text-classification)| Scraped tweets from Twitter and manually tagged. Features include: user name, location, Tweet time, tweet, label. Total features 6 2 files present: train and test set. (file: ZIP). |
|38. |[Ecommerce Text Classification](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/Ecommerce_Text_Classification.zip)| --- |[source](https://www.kaggle.com/datasets/saurabhshahane/ecommerce-text-classification)| classification based E-commerce text dataset for 4 categories - "Electronics", "Household", "Books" and "Clothing & Accessories". Features include: user name, location, Tweet time, tweet, label. Total features 2, 4 classes, total examples: 50425 entries.[Original description](https://zenodo.org/records/3355823) (file: ZIP). |
|39. |[Spam Text Message Classification](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/Spam_Text_Message_Classification.zip)| --- |[source](https://www.kaggle.com/datasets/team-ai/spam-text-message-classification)| Based spam classification. Text classification with 2 classes.  Total features 2, 2 classes.(file: ZIP). |
|40. |[Emotion Detection from Text](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/Emotion_Detection_from_Text.zip)| --- |[source](https://www.kaggle.com/datasets/pashupatigupta/emotion-detection-from-text)| Emotion detection from text data (multilabel text classification). The data is  a collection of tweets annotated with the emotions.  Total features 3, 13 classes, 40000 tweets.(file: ZIP). |
|41. |[Computational humor detection](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/Computational_humor.zip)| --- |[source](https://www.kaggle.com/datasets/deepcontractor/200k-short-texts-for-humor-detection)| Dataset for humor detection consisting of 200,000 formal short texts.  Total features 2, 2 classes, 200,000 sentences. [Original article](https://arxiv.org/abs/2004.12765) (file: ZIP). |
|42. |[AI generated text](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/AI_Generated_Text_Dataset.zip)| --- |[source](https://www.kaggle.com/datasets/sunilthite/llm-detect-ai-generated-text-dataset)| This Dataset contains both AI Generated Essay and Human Written.  28,000 essay written by student and AI generated by a mix of LLMs. Total features 2, 2 classes, 28,000 sentences. [Original article](https://arxiv.org/abs/2004.12765) (file: ZIP). |
|43. |[AI generated text](https://github.com/SalvatoreRa/tutorial/blob/main/datasets/AWS_Case_Studies_and_Blogs.zip)| --- |[source](https://www.kaggle.com/datasets/harshsinghal/aws-case-studies-and-blogs)| This dataset is meant as a corpus to test Retrieval Augmented Generation (RAG) with Large Language Models (LLM). (file: ZIP). It is a collection of text files of Amazon Web Services (AWS) case studies and blog articles related to Generative AI and Large Language Models (90 % of case studies and text articles). You have to clean from HTML elements to use them efficiently. 347 text files|
|44.|[Breast Cancer Wisconsin](https://raw.githubusercontent.com/SalvatoreRa/tutorial/main/datasets/Breast_Cancer_Wisconsin.csv)|--|[source](https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data)|Features are derived from a digitized image of a fine needle aspirate (FNA) taken from a breast mass, capturing various attributes of the cell nuclei observed in the image. The target variable is Diagnosis (M = malignant, B = benign), Class distribution: 357 benign, 212 malignant|
|45.|[MiniBooNE](https://raw.githubusercontent.com/SalvatoreRa/tutorial/main/datasets/MiniBooNE.zip)|--|[source]([https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data](https://www.openml.org/search?type=data&sort=runs&id=44128&status=active))|This dataset is taken from the MiniBooNE experiment and is used to distinguish electron neutrinos (signal) from muon neutrinos (background). This dataset is ordered. It first contains all signal observations, and then background observations. (n examples: 72998, n featues: 51, classes: 2, balanced)|



&nbsp;

# Dataset suggestion

A quick chart about which dataset to use for different tasks.

&nbsp;

![dataset task](https://github.com/SalvatoreRa/tutorial/blob/main/images/datasets.png?raw=true)

&nbsp;

# Usage in Python

To use the dataset in your project you can download them (but also remember that pandas read also CSV files from the web) or if you use in Colab:

for CSV file 

```Python
#example for a dataset
#you can read from the directory or directly from the URL
data_dir = "https://raw.githubusercontent.com/SalvatoreRa/tutorial/main/datasets/Boston.csv"
df = pd.read_csv(data_dir)
```

If the file is contained in a zip.file, to upload in Google Colab

```Python
import sys
import os
import pandas as pd
#this is for unzipping and read the file
!wget https://github.com/SalvatoreRa/tutorial/blob/main/datasets/IMDB.zip?raw=true
!unzip IMDB.zip?raw=true
imdb_data=pd.read_csv("IMDB Dataset.csv")
```
if the file is JSON reading it is as simple as:

```Python
#example for a dataset
#you can read from the directory or directly from the URL
data_dir ='https://raw.githubusercontent.com/SalvatoreRa/tutorial/main/datasets/mammoth_3d.json'
df =pd.read_json(url)
```

&nbsp;

## Usage in R

It is very easy to direct in R

```R
#example for a dataset
#you can read from directory or directly from url
df <-read.csv("https://raw.githubusercontent.com/SalvatoreRa/tutorial/main/datasets/iris_flowers.csv")
head(df)

```
&nbsp;

# Additional Datasets 

I am listing here **additional dataset** that you can use with the provided link. The datasets listed cover different aspects of Machine learning and Artificial intelligence common tasks (computer Vision, Financial Analysis, Sentimental Analysis, Natural Language Processing, Autonomous Vehicles). If the dataset is available in multiple sources I am also adding alternative links (I check regularly and update the links that not working anymore).

| dataset |  Source | Description |
| ------- |  ------ |------ |
| US Healthcare Info | [link](https://www.kaggle.com/maheshdadhich/us-healthcare-data) | A survey of the US school systemâs finances |
| Image net | [link](https://image-net.org/) | The image dataset. If you really do not know: Hundred of thousands of photo from a thousand categories  |
| LSUN | [link](https://www.tensorflow.org/datasets/catalog/lsun) | Large scale images showing different objects from given categories like bedroom, tower etc.  |
| MS COCO | [link](https://cocodataset.org/) | Segmentation, comprehension and captioning of pictures.  |
| COIL-100 | [link](https://www1.cs.columbia.edu/CAVE/software/softlib/coil-100.php) | 100 different 360-rotation objects  |
| Visual Genoma | [link](http://visualgenome.org/) | Visual Genome is a dataset, a knowledge base, an ongoing effort to connect structured image concepts to language. |
| Google opena dataset| [link](https://ai.googleblog.com/2016/09/introducing-open-images-dataset.html) | 9 million URLs to images that have been annotated with labels spanning over 6000 categories  |
| Stanford Dogs Dataset | [link](http://vision.stanford.edu/aditya86/ImageNetDogs/) | The Stanford Dogs dataset contains images of 120 breeds of dogs from around the world.  |
| Indoor Scene Recognition | [link](http://web.mit.edu/torralba/www/indoor.html) | The database contains 67 Indoor categories, and a total of 15620 images. The number of images varies across categories, but there are at least 100 images per category |
| VQA  | [link](https://visualqa.org/) | VQA is a  dataset containing open-ended questions about images. More than 250000 images and questions that require an understanding of vision, language and commonsense knowledge to answer |
| Multi-Domain Sentiment Dataset | [link](https://www.cs.jhu.edu/~mdredze/datasets/sentiment/) | The Multi-Domain Sentiment Dataset contains product reviews taken from Amazon.com from many product types (domains). Some domains (books and dvds) have hundreds of thousands of reviews. Others (musical instruments) have only a few hundred. A bit old but used in different several scientific articles |
| Sentiment140  | [link](http://help.sentiment140.com/for-students/) | 160000 tweet, The data is a CSV with emoticons removed and polarity annotated (negative, neutral, positive) |
| Twitter US Airline Sentiment | [link](https://www.kaggle.com/crowdflower/twitter-airline-sentiment) | A sentiment analysis job about the problems of each major U.S. airline. Twitter data was scraped from February of 2015  |
| Enron Email Dataset | [link](https://www.cs.cmu.edu/~./enron/) | It contains data from about 150 users, mostly senior management of Enron, organized into folders. The corpus contains a total of about 0.5M messages.  |
| Amazon reviews | [link](https://snap.stanford.edu/data/web-Amazon.html)  [link](http://jmcauley.ucsd.edu/data/amazon/) | This dataset consists of reviews from amazon. The data span a period of 18 years, including ~35 million reviews up to March 2013. Reviews include product and user information, ratings, and a plaintext review |
| Google Books Ngrams | [link](https://aws.amazon.com/it/datasets/google-books-ngrams/) | A data set containing Google Books n-gram corpora  |
| Blog Authorship Corpus| [link](https://www.kaggle.com/rtatman/blog-authorship-corpus) | This dataset contains text from blogs written on or before 2004. Posts of 19,320 bloggers gathered from blogger.com in August 2004. The corpus incorporates a total of 681,288 posts and over 140 million words |
| Wikipedia Links Data | [link](https://code.google.com/archive/p/wiki-links/downloads) [link](http://www.iesl.cs.umass.edu/data/data-wiki-links)|  the Wikilinks dataset comprising of 40 million mentions over 3 million entities  |
| Hansards Text Chunks from the Canadian Parliament |  [link](https://metatext.io/datasets/hansards-canadian-parliament)|  Created by Natural Language Group - USC at 2001,  Dataset contains pairs of aligned text chunks (sentences or smaller fragments) from the official recordsof the 36th Canadian Parliament. in English language. Containing 1.3M in Text file format  |
| Jeopardy |  [link](https://www.kaggle.com/tunguz/200000-jeopardy-questions)|  over 200,000 questions from the Jeopardy quiz show |
| SMS Spam Compilation in English |  [link](https://www.kaggle.com/uciml/sms-spam-collection-dataset)|  The SMS Spam Collection is a set of SMS tagged messages that have been collected for SMS Spam research. It contains one set of SMS messages in English of 5,574 messages |
| SMS Spam Compilation in English |  [link](https://www.yelp.com/dataset)|  More than 8 million reviews, 160000 bussiness, are included in an open dataset  by Yelp |
| Berkeley DeepDrive BDD100k |  [link](https://bdd-data.berkeley.edu/)| More than 100,000 views of driving journeys of over 1,100 hours through various periods of the day and weather conditions |
| Baidu Apolloscapes |  [link](http://apolloscape.auto/)| Trajectory dataset, 3D Perception Lidar Object Detection and Tracking dataset including about 100K image frames, 80k lidar point cloud and 1000km trajectories for urban traffic. The dataset consisting of varying conditions and traffic densities which includes many challenging scenarios where vehicles, bicycles, and pedestrians move among one another. |
| comma2k19 |  [link](https://github.com/commaai/comma2k19)|  a dataset of over 33 hours of commute in California's 280 highway |
| Oxfordâs Robotic Car |  [link](https://robotcar-dataset.robots.ox.ac.uk/)| TThe Oxford RobotCar Dataset contains over 100 repetitions of a consistent route through Oxford, UK, captured over a period of over a year. The dataset captures many different combinations of weather, traffic and pedestrians, along with longer term changes such as construction and roadworks. |
| Cityscape Dataset |  [link](https://www.cityscapes-dataset.com/)| stereo video sequences recorded in street scenes from 50 different cities, with high quality pixel-level annotations of 5â¯000 frames in addition to a larger set of 20â¯000 weakly annotated frames |
| Traffic Sign Recognition  |  [link](http://apolloscape.auto/)| More than 10000+ traffic sign annotations |
| LISA traffic light |  [link](https://www.kaggle.com/mbornoe/lisa-traffic-light-dataset)| The database consists of continuous test and training video sequences, totaling 43,007 frames and 113,888 annotated traffic lights. |
| National Institute of Health X-Ray Dataset| [link](https://medpix.nlm.nih.gov/home) | This NIH Chest X-ray Dataset is comprised of 112,120 X-ray images with disease labels from 30,805 unique patients. To create these labels, the authors used Natural Language Processing to text-mine disease classifications from the associated radiological reports. The labels are expected to be >90% accurate and suitable for weakly-supervised learning.  |


&nbsp;

# Suggested Repositories 

I am listing here additional repositories that you can use with the provided link and a description.

The list is not exhaustive and I am planning to extend, please feel free to suggest addition.

| Repository | Link |  Description |
| ------- | ----------- | ------ |
| Kaggle | [link](https://www.kaggle.com/) | A great source for datasets, with code and competitions. |
| UCI machine learning | [link](https://archive.ics.uci.edu/ml/index.php) | One of the oldest repository, user contributed. Not all the dataset are clean, but you can download without  |
| School System Finance | [link](https://archive.ics.uci.edu/ml/index.php) | One of the oldest repository, user contributed. Not all the dataset are clean, but you can download without  |
| EU Open Data Portal | [link](https://data.europa.eu/en) | More than a 1 million datasets released by the EU about health, finance, science etc... |
| Data. gov | [link](https://www.data.gov/) | Data from various US government departments, but it can tricky to exploit the data |
| Quandl | [link](https://www.data.gov/) | Great source of economic and financial data |
| Word Bank | [link](https://data.worldbank.org/) | You can download data about population demographics, global economic and development indicators |
| IMF statistics | [link](https://www.imf.org/en/Data) | International Monetary Fund data about international finaces, debt rate, etc... |
| American Economic Association  | [link](https://data.worldbank.org/) | US macroeconomic data concerning employment, economic output, and other  variables |
| Google Trends| [link](https://trends.google.com/trends/?q=google&ctab=0&geo=all&date=all&sort=0) | Internet search activity details and  trends |
| Project Gutenberg| [link](https://www.gutenberg.org/) | Project Gutenberg is a library of over 60,000 free eBooks |
| LINQS| [link](https://linqs.soe.ucsc.edu/data) | different relational dataset for graph analysis |
| PyTorch Geometric| [link](https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html) | many different relational dataset for graph analysis |

&nbsp;

# Contributing

Feel free to suggest other datasets and repositories


# License

This project is licensed under the **MIT License** 

# Bugs/Issues

Comment or open an issue on Github
